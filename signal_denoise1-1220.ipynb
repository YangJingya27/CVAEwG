{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba86355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DateSet, numpy2gpu,load_split_data\n",
    "from utils import gen_tests_of_deblur,x_post_sample_modify,prior_mean_cov\n",
    "from utils import sample_cumulated_sum\n",
    "from function import get_x_ml\n",
    "from visualize import printdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1bdd32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_range: [0.001, 0.1]\n",
      "noise_num: 5000\n",
      "M_samples_per_para: 40\n",
      "x_dim: 50\n",
      "data_dim: 50\n",
      "sigma_prior: 0.01\n",
      "    H: (50, 50)\n",
      "data_file_prefix: data\\signal_denoise_mu5000_0.001_0.1_M40\n",
      "---------------------------------------------------------------------------\n",
      "number of samples: 5000*  40  (noise_num*M_samples_per_para)\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run problem_setting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccde5b7",
   "metadata": {},
   "source": [
    "# load model and simulate test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1ceed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type1_12_14_ls5_lr4e-06\n",
      "epochs: 10\n",
      "batch_size: 64\n",
      "encoder_layer_sizes: [101, 60, 100, 300, 700, 1400, 4000]\n",
      "decoder_layer_sizes: [4000, 1400, 700, 300, 100, 60, 10, 1]\n",
      "latent_size: 5\n",
      "print_every: 5000\n",
      "fig_root: figs\n",
      "conditional: True\n",
      "sigma_range: [0.001, 0.1]\n",
      "noise_num: 5000\n",
      "M_samples_per_para: 40\n",
      "x_dim: 50\n",
      "data_dim: 50\n",
      "sigma_prior: 0.01\n",
      "    H: (50, 50)\n",
      "data_file_prefix: data/signal_denoise_mu5000_0.001_0.1_M40\n"
     ]
    }
   ],
   "source": [
    "model_file_name = 'type1_12_14_ls5_lr4e-06' #??\n",
    "\n",
    "args = np.load(os.path.join('saved_model',model_file_name)+\"_args.npy\",allow_pickle=True).item()\n",
    "hypers = np.load(os.path.join('saved_model',model_file_name)+\"_hypers.npy\",allow_pickle=True).item() ##############??\n",
    "\n",
    "print(model_file_name)\n",
    "printdict(args),printdict(hypers)\n",
    "\n",
    "cvae = torch.load(os.path.join('saved_model',model_file_name)+\".pth\") #??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686616c-7680-4f9a-8f94-a4e4a0dd67b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effdeb3e-bb22-40e8-bc14-57814a23752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_ml(y,hypers):\n",
    "    \"\"\"\n",
    "    max p(y|x)\n",
    "    \"\"\"\n",
    "    # y is  a ndarray\n",
    "    n,m = hypers['data_dim'],hypers['x_dim']\n",
    "    data = y.flatten()\n",
    "    # Construct the problem.\n",
    "\n",
    "    x = cp.Variable([m,1])\n",
    "    f = cp.sum_squares(data-x.flatten())\n",
    "    objective = cp.Minimize(f)\n",
    "    p = cp.Problem(objective)\n",
    "\n",
    "    # Assign a value to gamma and find the optimal x.\n",
    "    result = p.solve(solver=cp.SCS,verbose=False)\n",
    "    return (x.value).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb06b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_post_sample_modify(m,sigma_prior,sigma_noise,y):\n",
    "    I=np.identity(m)\n",
    "    T_pr_inv = sigma_prior**(-2) * I\n",
    "    T_obs_inv = sigma_noise**(-2) * I\n",
    "    post_cov = np.linalg.inv(T_pr_inv+T_obs_inv)\n",
    "    post_mean = post_cov@(T_obs_inv@y)\n",
    "    \n",
    "    post_cov_L = np.linalg.cholesky(post_cov)\n",
    "    x_post_sample = post_mean+post_cov_L@np.random.randn(m,1)\n",
    "    return x_post_sample,post_mean,post_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e26097-02e1-40d8-b363-7663edd41ecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 产生真实数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fca047fa-0d4d-40fe-84b7-f996c99bd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = hypers['x_dim']\n",
    "n = 20 # 一共有10个数据\n",
    "C = np.identity(x_dim) * (hypers['sigma_prior']**2)\n",
    "x = np.random.multivariate_normal([0] * x_dim, C,n) # [M,x_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01e12ef3-c34a-47ad-ac6c-0b8d81487cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(x)\n",
    "# save = pd.DataFrame(np_data, columns = ['year', 'month', 'day']) \n",
    "x.to_csv('D://LiulanqiDownload//jupyter code//signal_denoise//x.csv',index=False,header=False)  #index=False,header=False表示不保存行索引和列标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d898b62e-787c-4ce7-8b07-0f408c2bab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('D://LiulanqiDownload//jupyter code//signal_denoise//x.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d3f5ab5-4041-4b44-9d85-4dff004715d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1947febb-6c18-4b0b-9a69-d2f54ba6cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers['sigma_noise'] = 0.08\n",
    "sigma_noise = hypers['sigma_noise']\n",
    "np.random.seed(10)\n",
    "Hx = x\n",
    "b = np.random.randn(n,50) * sigma_noise\n",
    "y = Hx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c86779-e8fb-451b-9bf3-c5e21679a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(x)\n",
    "# save = pd.DataFrame(np_data, columns = ['year', 'month', 'day']) \n",
    "y.to_csv('D://LiulanqiDownload//jupyter code//signal_denoise//y.csv',index=False,header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62bac6-6ceb-4100-90fe-84964ddebb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "133389f2-7391-45ee-bf5f-c429051ba641",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 没有标准化的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c80305e-c66a-4161-8e0e-f2eb947382ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CVAE_within_Gibbd] noise_gt: 0.01 | rmse 0.0088, noise_est: 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CVAE_within_Gibbd] noise_gt: 0.03 | rmse 0.0094, noise_est: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CVAE_within_Gibbd] noise_gt: 0.05 | rmse 0.0102, noise_est: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CVAE_within_Gibbd] noise_gt: 0.08 | rmse 0.0111, noise_est: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sigma_true in [0.01,0.03,0.05,0.08]:\n",
    "    hypers['sigma_noise'] = sigma_true\n",
    "    sigma_noise = hypers['sigma_noise']\n",
    "    np.random.seed(0)\n",
    "    Hx = x\n",
    "    b = np.random.randn(n,50) * sigma_noise\n",
    "    y = Hx + b\n",
    "    \n",
    "    THETA = []\n",
    "    RMSE = []\n",
    "    X = []\n",
    "    T = []\n",
    "    init=[]\n",
    "    \n",
    "    \n",
    "    for j in tqdm(range(n)):    \n",
    "        # def Gibbs_sample(N,use_sample_size,x_truth,y,hypers,show_step=200,theta_truth=None):\n",
    "        N = 1000\n",
    "        use_sample_size = 500\n",
    "        x_truth = x[j].reshape(-1,1)\n",
    "        theta_truth = np.zeros(1)#??\n",
    "        m = hypers['x_dim']\n",
    "        y_j = y[j]\n",
    "\n",
    "        x_0 =  get_x_ml(y_j,hypers)\n",
    "        x_init_value = x_0\n",
    "        init.append(x_init_value)\n",
    "        \n",
    "        x_sum,x_square_sum = np.zeros_like(x_truth),np.zeros_like(x_truth)\n",
    "        theta_sum,theta_square_sum = np.zeros_like(theta_truth),np.zeros_like(theta_truth)  \n",
    "\n",
    "        z = torch.randn([1, args['latent_size']]).to(device)\n",
    "        for i in range(N):\n",
    "            # sample theta\n",
    "            c = torch.cat((torch.tensor(x_0).float(),torch.tensor(y_j.reshape(-1,1)).float()),dim=0).T.to(device)\n",
    "            theta_0_gpu = cvae.inference(z, c=c)\n",
    "            theta_0 = theta_0_gpu.detach().cpu().numpy()[0]\n",
    "          # 因为之前在训练网络的时候，训练数据的时候我们先标准化数据了。这个时候需要标准化回来。乘以的也是原本训练时候的均值与方差\n",
    "            # sample x\n",
    "            sigma = theta_0\n",
    "            T.append(sigma)\n",
    "\n",
    "            x_0,_,_ = x_post_sample_modify(m,hypers['sigma_prior'],sigma,y_j.reshape(-1,1))\n",
    "            X.append(np.sqrt(((x_0 - x_truth)**2).sum()/50))\n",
    "\n",
    "            if i>(N-use_sample_size):\n",
    "                theta_sum,theta_square_sum = sample_cumulated_sum(theta_sum,theta_square_sum,theta_0)\n",
    "                x_sum,x_square_sum = sample_cumulated_sum(x_sum,x_square_sum,x_0)   \n",
    "\n",
    "        x_mean = x_sum/use_sample_size\n",
    "        x_var = x_square_sum/use_sample_size-x_mean**2\n",
    "\n",
    "        theta_mean = theta_sum/use_sample_size\n",
    "        theta_var = theta_square_sum/use_sample_size-theta_mean**2\n",
    "        rmse = np.sqrt(((x_mean - x_truth)**2).sum()/50)\n",
    "\n",
    "        THETA.append(theta_mean)\n",
    "        RMSE.append(rmse)\n",
    "    \n",
    "    noise_mean = np.array(THETA).mean()\n",
    "    rmse_mean = np.array(RMSE).mean()\n",
    "    \n",
    "    \n",
    "    print('[CVAE_within_Gibbd] noise_gt: %.2f | rmse %.4f, noise_est: %.4f' % (\n",
    "            sigma_true, rmse_mean, noise_mean\n",
    "        ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3865ca84-9d4b-441c-8b9f-4dfaebb7aaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.03340898]),\n",
       " array([0.02791102]),\n",
       " array([0.0433258]),\n",
       " array([0.03114116]),\n",
       " array([0.04009191]),\n",
       " array([0.02717631]),\n",
       " array([0.04395394]),\n",
       " array([0.0455601]),\n",
       " array([0.02669987]),\n",
       " array([0.02897704]),\n",
       " array([0.0399254]),\n",
       " array([0.0436222]),\n",
       " array([0.03271861]),\n",
       " array([0.03485844]),\n",
       " array([0.0344599]),\n",
       " array([0.04069585]),\n",
       " array([0.04225967]),\n",
       " array([0.0459307]),\n",
       " array([0.03835168]),\n",
       " array([0.03783121])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7f32d7f-8c99-4251-b5e1-ed29cf97c6be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0397]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0411]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0556]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0477]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0452]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0286]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0349]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0514]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0469]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0373]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0428]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0468]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0533]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0420]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0542]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0357]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0449]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0425]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0559]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0497]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0432]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0443]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0435]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0327]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0543]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0320]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0365]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0503]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0485]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0512]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0516]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0534]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0464]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0584]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0558]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0500]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0348]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0531]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0445]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0452]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0398]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0509]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0180]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0412]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0509]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0421]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0508]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0571]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0414]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yang\\AppData\\Local\\Temp/ipykernel_20752/39504917.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  m = torch.cat((torch.tensor(linshi).float(),torch.tensor(y[0].reshape(-1,1)).float()),dim=0).T.to(device)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    # sample theta\n",
    "    linshi = torch.randn([50,1])\n",
    "    m = torch.cat((torch.tensor(linshi).float(),torch.tensor(y[0].reshape(-1,1)).float()),dim=0).T.to(device)\n",
    "    print(cvae.inference(z, c=m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fac746f0-4f6b-48a8-af31-d275fbe1cd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03302641041260213"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(THETA).mean() # 0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f82ec5-091e-4f6c-9753-70af5384d155",
   "metadata": {},
   "source": [
    "# AGEM signal denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "95eca8cd-6271-4786-bcae-80189f1b45b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, time 0.2 sec | noise_gt: 0.0100, noise_est: 0.0112 (0.0007) | rmse: 0.0119 (0.0016)\n",
      "epoch 1, time 0.2 sec | noise_gt: 0.0100, noise_est: 0.0118 (0.0009) | rmse: 0.0140 (0.0009)\n",
      "epoch 2, time 0.2 sec | noise_gt: 0.0100, noise_est: 0.0119 (0.0011) | rmse: 0.0143 (0.0007)\n",
      "epoch 3, time 0.2 sec | noise_gt: 0.0100, noise_est: 0.0119 (0.0012) | rmse: 0.0144 (0.0010)\n",
      "epoch 4, time 0.2 sec | noise_gt: 0.0100, noise_est: 0.0122 (0.0014) | rmse: 0.0145 (0.0009)\n",
      "epoch 5, time 0.2 sec | noise_gt: 0.0100, noise_est: 0.0123 (0.0014) | rmse: 0.0146 (0.0008)\n",
      "epoch 6, time 0.1 sec | noise_gt: 0.0100, noise_est: 0.0124 (0.0015) | rmse: 0.0147 (0.0009)\n",
      "epoch 7, time 0.1 sec | noise_gt: 0.0100, noise_est: 0.0124 (0.0013) | rmse: 0.0146 (0.0009)\n",
      "epoch 8, time 0.2 sec | noise_gt: 0.0100, noise_est: 0.0125 (0.0012) | rmse: 0.0144 (0.0010)\n",
      "epoch 9, time 0.1 sec | noise_gt: 0.0100, noise_est: 0.0124 (0.0012) | rmse: 0.0144 (0.0011)\n",
      "[AGEM] noise_gt: 0.01 | rmse 0.0144 (0.0011), noise_est: 0.0124 (0.0012)\n",
      "epoch 0, time 0.1 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0210 (0.0017)\n",
      "epoch 1, time 0.2 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 2, time 0.2 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 3, time 0.2 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 4, time 0.2 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 5, time 0.2 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 6, time 0.1 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 7, time 0.2 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 8, time 0.2 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "epoch 9, time 0.3 sec | noise_gt: 0.0300, noise_est: 0.0156 (0.0010) | rmse: 0.0224 (0.0012)\n",
      "[AGEM] noise_gt: 0.03 | rmse 0.0224 (0.0012), noise_est: 0.0156 (0.0010)\n",
      "epoch 0, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0228 (0.0026) | rmse: 0.0305 (0.0022)\n",
      "epoch 1, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 2, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 3, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 4, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 5, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 6, time 0.1 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 7, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 8, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "epoch 9, time 0.2 sec | noise_gt: 0.0500, noise_est: 0.0227 (0.0026) | rmse: 0.0310 (0.0020)\n",
      "[AGEM] noise_gt: 0.05 | rmse 0.0310 (0.0020), noise_est: 0.0227 (0.0026)\n",
      "epoch 0, time 0.2 sec | noise_gt: 0.0800, noise_est: 0.0365 (0.0036) | rmse: 0.0445 (0.0033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LiulanqiDownload\\jupyter code\\signal_denoise\\infovae\\无条件、复杂\\AGEMsolver.py:102: RuntimeWarning: overflow encountered in exp\n",
      "  replace = np.random.uniform(0, 1, x.shape[0]) < np.exp(log_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, time 0.1 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 2, time 0.1 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 3, time 0.2 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 4, time 0.2 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 5, time 0.1 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 6, time 0.2 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 7, time 0.1 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 8, time 0.2 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "epoch 9, time 0.2 sec | noise_gt: 0.0800, noise_est: 0.0363 (0.0037) | rmse: 0.0452 (0.0032)\n",
      "[AGEM] noise_gt: 0.08 | rmse 0.0452 (0.0032), noise_est: 0.0363 (0.0037)\n"
     ]
    }
   ],
   "source": [
    "from AGEMsolver import solve_agem\n",
    "import numpy as np\n",
    "\n",
    "def run_test():\n",
    "    x_dim = 50\n",
    "    sigma_prior = hypers['sigma_prior'] # 对应新方法的 sigma_prior\n",
    "    sigma_proposal = 0.01\n",
    "    sigma_noise_hat_init = 0.01 # 初始项\n",
    "    cov = np.identity(x_dim) * sigma_prior**2\n",
    "    x_test = x\n",
    "    x_true = x_test[:]\n",
    "\n",
    "    noise_shape = x_true.shape[1:]\n",
    "    n_dim = np.prod(noise_shape)\n",
    "\n",
    "\n",
    "    for noise in [0.01,0.03,0.05,0.08]: #??   # 对应sigma_noise ，为真实的噪音取值！\n",
    "        sigma_noise = [noise] * n_dim\n",
    "        sigma_noise = np.array(sigma_noise[:n_dim]).reshape(noise_shape)\n",
    "\n",
    "        rmse_mean, rmse_std, noise_mean, noise_std, variance_noise_hat_em = \\\n",
    "            solve_agem(x_true=x_true, sigma_noise=sigma_noise,\n",
    "                       sigma_prior=sigma_prior, sigma_noise_hat_init=sigma_noise_hat_init,\n",
    "                       sigma_proposal=sigma_proposal, type_proposal='mala',\n",
    "                       candidate='mean', em_epochs=10, sample_epochs=1000)\n",
    "\n",
    "        print('[AGEM] noise_gt: %.2f | rmse %.4f (%.4f), noise_est: %.4f (%.4f)' % (\n",
    "            noise, rmse_mean, rmse_std, noise_mean, noise_std\n",
    "        ))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e77fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 求解信号去噪问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32968da1-c864-4621-8dc3-5b3068671bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = 0.0505, 0.028 #？？\n",
    "\n",
    "c_mean = torch.mean(torch.cat((torch.tensor(x).float(),torch.tensor(y).float()),dim=1),dim=0,keepdim=True)\n",
    "c_std = torch.std(torch.cat((torch.tensor(x).float(),torch.tensor(y).float()),dim=1),dim=0,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f28f0a7-aa9b-4048-b9fc-3605a05e36e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 521.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 531.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 518.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 532.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 534.24it/s]\n"
     ]
    }
   ],
   "source": [
    "THETA = []\n",
    "RMSE = []\n",
    "for j in range(n):    \n",
    "    # def Gibbs_sample(N,use_sample_size,x_truth,y,hypers,show_step=200,theta_truth=None):\n",
    "    N = 1000\n",
    "    use_sample_size = 500\n",
    "    x_truth = x[j].reshape(-1,1)\n",
    "    theta_truth = np.zeros(1)#??\n",
    "    m = hypers['x_dim']\n",
    "    y_j = y[j]\n",
    "\n",
    "    x_0 =  get_x_ml(y_j,hypers)\n",
    "    x_init_value = x_0\n",
    "    np.random.seed(3)    \n",
    "    x_sum,x_square_sum = np.zeros_like(x_truth),np.zeros_like(x_truth)\n",
    "    theta_sum,theta_square_sum = np.zeros_like(theta_truth),np.zeros_like(theta_truth)  \n",
    "\n",
    "    z = torch.randn([1, args['latent_size']]).to(device)\n",
    "    for i in tqdm(range(N)):\n",
    "        # sample theta\n",
    "        c = torch.cat((torch.tensor(x_0).float(),torch.tensor(y_j.reshape(-1,1)).float()),dim=0).T.to(device)\n",
    "        c_norm = (c-c_mean.to(device))/c_std.to(device)\n",
    "        theta_0_gpu = cvae.inference(z, c=c_norm)\n",
    "        theta_0 = theta_0_gpu.detach().cpu().numpy()[0]\n",
    "      # 因为之前在训练网络的时候，训练数据的时候我们先标准化数据了。这个时候需要标准化回来。乘以的也是原本训练时候的均值与方差\n",
    "        theta_0 = theta_0*std + mean\n",
    "        # sample x\n",
    "        sigma = theta_0\n",
    "        \n",
    "        x_0,_,_ = x_post_sample_modify(m,hypers['sigma_prior'],sigma,y_j.reshape(-1,1))\n",
    "\n",
    "        if i>(N-use_sample_size):\n",
    "            theta_sum,theta_square_sum = sample_cumulated_sum(theta_sum,theta_square_sum,theta_0)\n",
    "            x_sum,x_square_sum = sample_cumulated_sum(x_sum,x_square_sum,x_0)   \n",
    "\n",
    "    x_mean = x_sum/use_sample_size\n",
    "    x_var = x_square_sum/use_sample_size-x_mean**2\n",
    "\n",
    "    theta_mean = theta_sum/use_sample_size\n",
    "    theta_var = theta_square_sum/use_sample_size-theta_mean**2\n",
    "    rmse = np.sqrt(((x_mean - x_truth)**2).sum()/50)\n",
    "    \n",
    "    THETA.append(theta_mean)\n",
    "    RMSE.append(rmse)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
