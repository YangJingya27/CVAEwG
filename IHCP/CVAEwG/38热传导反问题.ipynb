{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba86355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DateSet, numpy2gpu,load_split_data\n",
    "from utils import gen_tests_of_deblur,x_post_sample_modify,prior_mean_cov\n",
    "from utils import sample_cumulated_sum\n",
    "from function import get_x_ml,W_matrx_1,W_matrx_2\n",
    "from visualize import printdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1bdd32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma: [0.001, 0.005, 0.01]\n",
      "noise_num: 3\n",
      "M_samples_per_para: 50000\n",
      "x_dim: 26\n",
      "data_dim: 50\n",
      "    H: (50, 26)\n",
      "    W: (26, 26)\n",
      "data_file_prefix: data\\heat_conduction_mu3_[0.001, 0.005, 0.01]_M50000\n",
      "---------------------------------------------------------------------------\n",
      "number of samples: 3*  50000  (noise_num*M_samples_per_para)\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run problem_setting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccde5b7",
   "metadata": {},
   "source": [
    "# load model and simulate test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681cba14-6b8f-4a46-a7ef-ced6d7663895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes, encoder_layer_sizes, latent_size, decoder_layer_sizes,\n",
    "                 conditional=True, num_labels=0):\n",
    "        super().__init__()\n",
    "\n",
    "        if conditional:\n",
    "            assert num_labels > 0\n",
    "\n",
    "        assert type(encoder_layer_sizes) == list\n",
    "        assert type(layer_sizes) == list\n",
    "        assert type(latent_size) == int\n",
    "        assert type(decoder_layer_sizes) == list\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "        self.net = NN(layer_sizes)\n",
    "        self.encoder = Encoder(\n",
    "            encoder_layer_sizes, latent_size, conditional, num_labels)\n",
    "        self.decoder = Decoder(\n",
    "            decoder_layer_sizes, latent_size, conditional, num_labels)\n",
    "\n",
    "    def forward(self, x, unkown, data):\n",
    "        data = self.net(data)\n",
    "        class_data = torch.max(data, 1).indices.float().reshape(-1, 1)\n",
    "        class_data = class_data @ torch.ones(1, 50)\n",
    "        c = torch.cat([unkown, class_data], dim=1)\n",
    "        means, log_var = self.encoder(x, c)\n",
    "        z = self.reparameterize(means, log_var)\n",
    "        recon_x = self.decoder(z, c)\n",
    "\n",
    "        return recon_x, z, data, class_data\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + eps * std\n",
    "\n",
    "    def inference(self, z, unkown, data):\n",
    "        data = self.net(data)\n",
    "        class_data = torch.max(data, 1).indices.float().reshape(-1, 1)\n",
    "        class_data = class_data @ torch.ones(1, 50)\n",
    "        c = torch.cat([unkown, class_data], dim=1)\n",
    "        recon_x = self.decoder(z, c)\n",
    "        return recon_x,data,class_data\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes, latent_size, conditional, num_labels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conditional = conditional\n",
    "        if self.conditional:\n",
    "            layer_sizes[0] += num_labels\n",
    "\n",
    "        self.MLP = nn.Sequential()\n",
    "\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            self.MLP.add_module(name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "\n",
    "            self.MLP.add_module(name=\"A{:d}\".format(i), module=nn.LeakyReLU())\n",
    "\n",
    "        self.linear_means = nn.Linear(layer_sizes[-1], latent_size)\n",
    "        self.linear_log_var = nn.Linear(layer_sizes[-1], latent_size)\n",
    "\n",
    "    def forward(self, x, c=None):\n",
    "\n",
    "        if self.conditional:\n",
    "            x = torch.cat((x, c), dim=-1)\n",
    "\n",
    "        x = self.MLP(x)\n",
    "\n",
    "        means = self.linear_means(x)\n",
    "        log_vars = self.linear_log_var(x)\n",
    "\n",
    "        return means, log_vars\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes, latent_size, conditional, num_labels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.MLP = nn.Sequential()\n",
    "        self.last_par = torch.nn.parameter.Parameter(torch.normal(0, 0.1, size=(4, 1)))\n",
    "\n",
    "        self.conditional = conditional\n",
    "        if self.conditional:\n",
    "            input_size = latent_size + num_labels\n",
    "        else:\n",
    "            input_size = latent_size\n",
    "\n",
    "        for i, (in_size, out_size) in enumerate(zip([input_size] + layer_sizes[:-1], layer_sizes)):\n",
    "            self.MLP.add_module(name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "            if i + 2 < len(layer_sizes):\n",
    "                # self.MLP.add_module(name=\"A{:d}\".format(i), module=nn.BatchNorm1d(out_size))\n",
    "                self.MLP.add_module(name=\"A{:d}\".format(i), module=nn.LeakyReLU())\n",
    "            # else:\n",
    "            #     self.MLP.add_module(name=\"Output\", module=nn.Softplus())#[batchsize,layer_sizes[-1]]\n",
    "\n",
    "    # 最后一层不可以是1了...只能是指定的类别\n",
    "    def forward(self, z, c):\n",
    "\n",
    "        if self.conditional:\n",
    "            z = torch.cat((z, c), dim=1)\n",
    "        x = self.MLP(z)\n",
    "        out = x\n",
    "        return out\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, layer_size):\n",
    "        super(NN, self).__init__()  # 调用父类的初始化函数\n",
    "        assert type(layer_size) == list\n",
    "        self.classMLP = nn.Sequential()\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_size[:-1], layer_size[1:])):\n",
    "            self.classMLP.add_module(name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "            if i + 2 < len(layer_size):\n",
    "                self.classMLP.add_module(name=\"A{:d}\".format(i), module=nn.ReLU())\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = self.classMLP(data)\n",
    "        data = torch.nn.functional.softmax(data,dim=1)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb06b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_post_sample_modify(W,H,m,sigma,y,alpha):\n",
    "    sigma = sigma + 1e-8\n",
    "    lamda = 2*alpha/(sigma**2)\n",
    "#     T_pr_inv = np.linalg.inv(W/lamda)\n",
    "    T_pr_inv = W * lamda \n",
    "    post_cov = np.linalg.inv((1/sigma**2)* H.T@H + T_pr_inv)\n",
    "    post_mean = post_cov@(H.T@y* (1/(sigma))**2)\n",
    "    \n",
    "    post_cov_L = np.linalg.cholesky(post_cov)\n",
    "    x_post_sample = post_mean+post_cov_L@np.random.randn(m,1)\n",
    "    return x_post_sample,post_mean,post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1ceed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0506_ls5_cvae_lr9.599999999999998e-05\n",
      "epochs: 20\n",
      "batch_size: 128\n",
      "layer_sizes: [50, 100, 200, 100, 50, 30, 3]\n",
      "encoder_layer_sizes: [77, 30, 12, 5]\n",
      "decoder_layer_sizes: [40, 20, 10, 1]\n",
      "latent_size: 5\n",
      "print_every: 5000\n",
      "fig_root: figs\n",
      "conditional: True\n",
      "sigma: [0.001, 0.005, 0.01]\n",
      "noise_num: 3\n",
      "M_samples_per_para: 50000\n",
      "x_dim: 26\n",
      "data_dim: 50\n",
      "    H: (50, 26)\n",
      "    W: (26, 26)\n",
      "data_file_prefix: heat_conduction_mu3_M50000\n"
     ]
    }
   ],
   "source": [
    "#只分3类 \n",
    "model_file_name = '0506_ls5_cvae_lr9.599999999999998e-05' #?? 0.01 0.0076 0.0027\n",
    "# 分为5类 model_file_name = '0505_cvae_lr0.0005500000000000001_accuracy0.609375' \n",
    "# 分成8 类 \n",
    "# model_file_name ='0512_cvae_lr0.0011499999999999998_accuracy0.6875'#'0510_cvae_lr0.004600000000000001_accuracy0.7578125'#'0510_cvae_lr0.0051_accuracy0.6484375'0.008,0.008,0.004 #'0510_cvae_lr0.0006000000000000002_accuracy0.6640625'##'0510_cvae_lr0.004600000000000001_accuracy0.7578125'#''\n",
    "args = np.load(os.path.join('saved_model',model_file_name)+\"_args.npy\",allow_pickle=True).item()\n",
    "hypers = np.load(os.path.join('saved_model',model_file_name)+\"_hypers.npy\",allow_pickle=True).item()\n",
    "\n",
    "print(model_file_name)\n",
    "printdict(args),printdict(hypers)\n",
    "\n",
    "cvae = torch.load(os.path.join('saved_model',model_file_name)+\".pth\") #??\n",
    "cvae =  cvae.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2752cae-d0fc-4bc4-9b9e-ef8f56ba1c38",
   "metadata": {},
   "source": [
    "$\\sigma_{obs} = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc3fbac9-de62-4186-9091-193ba6cbff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b5e421e-f33c-41a3-a7db-442bf1267c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1977.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_true:0.01,sigma_mean:[[0.01002861]],sigma_var:[[0.00061068]]\n",
      "0.041445736177933616 0.04161387022752196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "N = 10000\n",
    "y_true = np.array(pd.read_csv('y_true.csv'))\n",
    "use_sample_size = 5000\n",
    "x_true = np.array(pd.read_csv('qt_true.csv',header = None))\n",
    "\n",
    "H = hypers['H']\n",
    "H_arr = np.array(H)\n",
    "W = W_matrx_1()\n",
    "alpha = 2.5e-2\n",
    "m = hypers['x_dim']\n",
    "\n",
    "\n",
    "y= np.array(pd.read_csv('tradition100000_0.01.csv',header=None))\n",
    "x_traditional = np.array(pd.read_csv('y100000_0.01.csv',header=None))\n",
    "sigma_noise = 0.01\n",
    "\n",
    "theta_truth = np.zeros(1)#??\n",
    "\n",
    "x_0 =  get_x_ml(y,hypers)\n",
    "x_init_value = x_0\n",
    "# np.random.seed(7)    \n",
    "x_sum,x_square_sum = np.zeros_like(x_true),np.zeros_like(x_true)\n",
    "theta_sum,theta_square_sum = np.zeros_like(theta_truth),np.zeros_like(theta_truth)  \n",
    "\n",
    "THETA= []\n",
    "X = []\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    # sample theta\n",
    "    c = torch.cat((torch.tensor(x_0).float(),torch.tensor(y).float()),dim=0).T\n",
    "    z = torch.randn([c.size(0), args['latent_size']])\n",
    "    theta_0,_,classes = cvae.inference(z,torch.tensor(x_0.T).float(),torch.tensor(y.T).float())\n",
    "    # theta_0,data = cvae.inference(z,torch.tensor(x_0.T).float(),torch.tensor(y.T).float()) #??\n",
    "    theta_0 = theta_0.detach().numpy()\n",
    "    sigma = theta_0\n",
    "\n",
    "    \n",
    "    x_0,_,_ = x_post_sample_modify(W,H_arr,m,sigma,y,alpha)\n",
    "    if i>(N-use_sample_size-1):\n",
    "        theta_sum,theta_square_sum = sample_cumulated_sum(theta_sum,theta_square_sum,theta_0)\n",
    "        x_sum,x_square_sum = sample_cumulated_sum(x_sum,x_square_sum,x_0)   \n",
    "    THETA.append(sigma[0])\n",
    "    X.append(x_0)\n",
    "\n",
    "x_mean = x_sum/use_sample_size\n",
    "x_var = x_square_sum/use_sample_size-x_mean**2\n",
    "\n",
    "theta_mean = theta_sum/use_sample_size\n",
    "theta_var = theta_square_sum/use_sample_size-theta_mean**2\n",
    "\n",
    "print(f'sigma_true:{sigma_noise},sigma_mean:{theta_mean},sigma_var:{np.sqrt(theta_var)}')\n",
    "\n",
    "x = np.linspace(0, 1, m)\n",
    "interval0 = [1 if (i < 0.4) else 0 for i in x]\n",
    "interval1 = [1 if (i >= 0.4 and i < 0.8) else 0 for i in x]\n",
    "interval2 = [1 if (i >= 0.8) else 0 for i in x]\n",
    "y = (2.5 * x) * interval0 + (2 - 2.5 * x) * interval1 + np.array([0]*m) * interval2\n",
    "\n",
    "print(np.sqrt(np.sum((x_mean.flatten()-y)**2)/x.shape[0]),np.sqrt(np.sum((x_traditional.flatten()-y)**2)/x.shape[0]))######################3！！！！！！！！！！！！！！！1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a6fb777-8824-46c6-b20f-478faa6b854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'D:\\LiulanqiDownload\\pycharm\\code\\heat_conduction_\\metroplis-within-gibbs\\data821'\n",
    "np.save(os.path.join(path,f'CwG_xmean_{sigma_noise}.npy'),x_mean)\n",
    "np.save(os.path.join(path,f'CwG_xvar_{sigma_noise}.npy'),x_var)\n",
    "np.save(os.path.join(path,f'CwG_theta_{sigma_noise}.npy'), np.array(THETA))\n",
    "np.save(os.path.join(path,f'CwG_x_{sigma_noise}.npy'), np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c14f82-2eea-46f8-b510-09c98fa27fb2",
   "metadata": {},
   "source": [
    "$\\sigma_{obs} = 0.005$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68a1db-d4ff-4f62-a53f-ec288e46e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     np.random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "200b1af1-3796-49b7-918b-e0023b27c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:04<00:00, 2164.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行时间 : 4.622421979904175 秒\n",
      "sigma_true:0.005,sigma_mean:[[0.00766732]],sigma_std:[[0.00067341]]\n",
      "0.030785173406453502 0.03476813655322245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "y_true = np.array(pd.read_csv('y_true.csv'))\n",
    "use_sample_size = 5000\n",
    "x_true = np.array(pd.read_csv('qt_true.csv',header = None))\n",
    "\n",
    "H = hypers['H']\n",
    "H_arr = np.array(H)\n",
    "W = W_matrx_1()\n",
    "alpha = 1e-2\n",
    "m = hypers['x_dim']\n",
    "\n",
    "\n",
    "# y= np.array(pd.read_csv('tradition100000_0.005.csv',header=None))\n",
    "y = np.array(pd.read_csv('tradition100000_0.005_test.csv',header=None)).T\n",
    "x_traditional_005 = np.array(pd.read_csv('y100000_0.005.csv',header=None))\n",
    "sigma_noise = 0.005\n",
    "\n",
    "theta_truth = np.zeros(1)#??\n",
    "\n",
    "x_0 =  get_x_ml(y,hypers)\n",
    "x_init_value = x_0\n",
    "np.random.seed(7)    \n",
    "x_sum,x_square_sum = np.zeros_like(x_true),np.zeros_like(x_true)\n",
    "theta_sum,theta_square_sum = np.zeros_like(theta_truth),np.zeros_like(theta_truth)  \n",
    "\n",
    "THETA= []\n",
    "X = []\n",
    "start = time.time()\n",
    "for i in tqdm(range(N)):\n",
    "    # sample theta\n",
    "    c = torch.cat((torch.tensor(x_0).float(),torch.tensor(y).float()),dim=0).T\n",
    "    z = torch.randn([c.size(0), args['latent_size']])\n",
    "#     theta_0 = cvae.inference(z, c=c).detach().numpy()\n",
    "#     sigma = theta_0\n",
    "    # theta_0,data = cvae.inference(z,torch.tensor(x_0.T).float(),torch.tensor(y.T).float())\n",
    "    theta_0,_,classes = cvae.inference(z,torch.tensor(x_0.T).float(),torch.tensor(y.T).float())\n",
    "    theta_0 = theta_0.detach().numpy()\n",
    "    sigma = theta_0\n",
    "\n",
    "    x_0,_,_ = x_post_sample_modify(W,H_arr,m,sigma,y,alpha)\n",
    "    if i>(N-use_sample_size-1):\n",
    "        theta_sum,theta_square_sum = sample_cumulated_sum(theta_sum,theta_square_sum,theta_0)\n",
    "        x_sum,x_square_sum = sample_cumulated_sum(x_sum,x_square_sum,x_0)   \n",
    "    THETA.append(sigma[0])\n",
    "    X.append(x_0)\n",
    "\n",
    "x_mean = x_sum/use_sample_size\n",
    "x_var = x_square_sum/use_sample_size-x_mean**2\n",
    "\n",
    "theta_mean = theta_sum/use_sample_size\n",
    "theta_var = theta_square_sum/use_sample_size-theta_mean**2\n",
    "end = time.time()\n",
    "\n",
    "print('运行时间 : %s 秒' % (end - start))\n",
    "print(f'sigma_true:{sigma_noise},sigma_mean:{theta_mean},sigma_std:{np.sqrt(theta_var)}')\n",
    "\n",
    "x = np.linspace(0, 1, m)\n",
    "interval0 = [1 if (i < 0.4) else 0 for i in x]\n",
    "interval1 = [1 if (i >= 0.4 and i < 0.8) else 0 for i in x]\n",
    "interval2 = [1 if (i >= 0.8) else 0 for i in x]\n",
    "y = (2.5 * x) * interval0 + (2 - 2.5 * x) * interval1 + np.array([0]*m) * interval2\n",
    "\n",
    "print(np.sqrt(np.sum((x_mean.flatten()-y)**2)/x.shape[0]),np.sqrt(np.sum((x_traditional_005.flatten()-y)**2)/x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b573ca3c-52d9-4414-85ad-932bc0e02b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'D:\\LiulanqiDownload\\pycharm\\code\\heat_conduction_\\metroplis-within-gibbs\\data821'\n",
    "np.save(os.path.join(path,f'CwG_xmean_{sigma_noise}.npy'),x_mean)\n",
    "np.save(os.path.join(path,f'CwG_xvar_{sigma_noise}.npy'),x_var)\n",
    "np.save(os.path.join(path,f'CwG_theta_{sigma_noise}.npy'), np.array(THETA))\n",
    "np.save(os.path.join(path,f'CwG_x_{sigma_noise}.npy'), np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ef5e7-a28b-4ede-ac55-d2c7af4220c6",
   "metadata": {},
   "source": [
    "$\\sigma_{obs} = 0.001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5035866e-063e-4f7c-b3ce-473c0b44f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     np.random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3fb6862-b4fc-41d5-a657-8872d05fe618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:04<00:00, 2177.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行时间 : 4.595203638076782 秒\n",
      "sigma_true:0.001,sigma_mean:[[0.00277777]],sigma_std:[[0.00030574]]\n",
      "0.015024912106400312 0.01491136089527157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "y_true = np.array(pd.read_csv('y_true.csv'))\n",
    "use_sample_size = 5000\n",
    "x_true = np.array(pd.read_csv('qt_true.csv',header = None))\n",
    "\n",
    "H = hypers['H']\n",
    "H_arr = np.array(H)\n",
    "W = W_matrx_1()\n",
    "alpha = 5e-4\n",
    "m = hypers['x_dim']\n",
    "\n",
    "\n",
    "y= np.array(pd.read_csv('tradition100000_0.001.csv',header=None))\n",
    "x_traditional_001 = np.array(pd.read_csv('y100000_0.001.csv',header=None))\n",
    "sigma_noise = 0.001\n",
    "\n",
    "theta_truth = np.zeros(1)#??\n",
    "\n",
    "x_0 =  get_x_ml(y,hypers)\n",
    "x_init_value = x_0\n",
    "np.random.seed(7)    \n",
    "x_sum,x_square_sum = np.zeros_like(x_true),np.zeros_like(x_true)\n",
    "theta_sum,theta_square_sum = np.zeros_like(theta_truth),np.zeros_like(theta_truth)  \n",
    "\n",
    "THETA= []\n",
    "X = []\n",
    "start = time.time()\n",
    "for i in tqdm(range(N)):\n",
    "    # sample theta\n",
    "    c = torch.cat((torch.tensor(x_0).float(),torch.tensor(y).float()),dim=0).T\n",
    "    z = torch.randn([c.size(0), args['latent_size']])\n",
    "#     theta_0 = cvae.inference(z, x_0,y).detach().numpy()\n",
    "#     sigma = theta_0\n",
    "# #     print(c,z,sigma)\n",
    "    # theta_0,classes = cvae.inference(z,torch.tensor(x_0.T).float(),torch.tensor(y.T).float())\n",
    "    theta_0,_,classes = cvae.inference(z,torch.tensor(x_0.T).float(),torch.tensor(y.T).float())\n",
    "    theta_0 = theta_0.detach().numpy()\n",
    "    sigma = theta_0\n",
    "\n",
    "\n",
    "    x_0,_,_ = x_post_sample_modify(W,H_arr,m,sigma,y,alpha)\n",
    "    if i>(N-use_sample_size):\n",
    "        theta_sum,theta_square_sum = sample_cumulated_sum(theta_sum,theta_square_sum,theta_0)\n",
    "        x_sum,x_square_sum = sample_cumulated_sum(x_sum,x_square_sum,x_0)   \n",
    "    THETA.append(sigma[0])\n",
    "    X.append(x_0)\n",
    "\n",
    "x_mean = x_sum/use_sample_size\n",
    "x_var = x_square_sum/use_sample_size-x_mean**2\n",
    "\n",
    "theta_mean = theta_sum/use_sample_size\n",
    "theta_var = theta_square_sum/use_sample_size-theta_mean**2\n",
    "end = time.time()\n",
    "\n",
    "print('运行时间 : %s 秒' % (end - start))\n",
    "print(f'sigma_true:{sigma_noise},sigma_mean:{theta_mean},sigma_std:{np.sqrt(theta_var)}')\n",
    "\n",
    "x = np.linspace(0, 1, m)\n",
    "interval0 = [1 if (i < 0.4) else 0 for i in x]\n",
    "interval1 = [1 if (i >= 0.4 and i < 0.8) else 0 for i in x]\n",
    "interval2 = [1 if (i >= 0.8) else 0 for i in x]\n",
    "y = (2.5 * x) * interval0 + (2 - 2.5 * x) * interval1 + np.array([0]*m) * interval2\n",
    "\n",
    "print(np.sqrt(np.sum((x_mean.flatten()-y)**2)/x.shape[0]),np.sqrt(np.sum((x_traditional_001.flatten()-y)**2)/x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756575bb-d3ee-42f0-af41-778ca583d6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8455272d-2aba-4975-a423-eba7bce0e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'D:\\LiulanqiDownload\\pycharm\\code\\heat_conduction_\\metroplis-within-gibbs\\data821'\n",
    "np.save(os.path.join(path,f'CwG_xmean_{sigma_noise}.npy'),x_mean)\n",
    "np.save(os.path.join(path,f'CwG_xvar_{sigma_noise}.npy'),x_var)\n",
    "np.save(os.path.join(path,f'CwG_theta_{sigma_noise}.npy'), np.array(THETA))\n",
    "np.save(os.path.join(path,f'CwG_x_{sigma_noise}.npy'), np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87651b9f-5f47-46f3-9b04-6bc2839369f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b90f60-1b90-45d7-9f18-0f196f7860a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
